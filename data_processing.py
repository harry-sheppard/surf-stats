# -*- coding: utf-8 -*-
"""CSP restart0

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vftsLHUXDMWnD8wqpDhjB30PZBwUC9yW

# Dependancies
"""

!pip install netCDF4
!pip install pyestimate
import netCDF4 as nc
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.colors as colors
from scipy import stats
from pyestimate import sin_param_estimate
folder_path = "/content/drive/MyDrive/Colab Notebooks/Colab Files/Wave_Wind_(42,-11)_(57,0)"
nc_files = [f for f in os.listdir(folder_path) if f.endswith(".nc")]

"""# Upload new Dataset"""

# Get a list of all .nc files in the folder
nc_files = [f for f in os.listdir(folder_path) if f.endswith(".nc")]
#print(nc_files)

all_dataframes = []

for filename in nc_files:
  nc_file = os.path.join(folder_path, filename)
  dataset = nc.Dataset(nc_file, "r")

  data = {}

  for variable_name in dataset.variables:
    variable_data = dataset.variables[variable_name][:]
    data[variable_name] = variable_data
  #print(dataset.variables)

  df = pd.DataFrame(data)

  df["SATELLITE"] = [filename.split("MW_")[1].split("_FV")[0]]*len(df["TIME"])
  #print(df["SATELLITE"][0])

  all_dataframes.append(df)

merged_df = pd.concat(all_dataframes, ignore_index=True)

merged_df.to_csv("merged_data.csv", index=False)

print("All .nc files merged and saved to merged_data.csv")

"""For each file in the dataset:
* The netCDF4 library was used to convert the downloaded files from ".nc" files to a netCDF dataset.
* Column names were extracted from this dataset, and a Python dictionary, "data", was created to hold the heading:value pairs.
* Pandas could then be used to convert this dictionary into a dataframe type, "df".
* This dataframe was then appended to a running dataframe, "all_dataframes".

Once all files in the dataset had been appended, "merged_df" was created and saved to a CSV file.

# Reset
"""

read_file = "/content/drive/MyDrive/Colab Notebooks/Colab Files/merged_data.csv"
original_df = pd.read_csv(read_file)

"""* To avoid having to repeat this lengthy process on every startup, a new copy of the original dataframe could be initialised from the CSV file"""

df = original_df.copy()
df.head()

desired_quantities = ["TIME", "LATITUDE", "LONGITUDE", "SWH_KU_CAL", "BOT_DEPTH"]

#df = pd.read_csv("merged_data.csv")

#print(df.columns)

for column in df.columns:
  if column not in desired_quantities:
    df = df.drop(column, axis=1)
    #print(column)

df = df.rename(columns={"SWH_KU_CAL": "WAVE_HEIGHT", "TIME": "NUM_TIME"})

df.to_csv("filtered_data.csv", index=False)

print("Filtered data saved to filtered_data.csv")
df.head()

"""* Unwanted columns in the data were dropped, and the names of headings were altered to be clearer.
* Data now only contains the headings, "Num_Time, Latitude, Longitude, Wave_Height, and Bot_Depth".
"""

def num_to_date(time_format):
#convert "TIME" from "days since 1985..." to "YYYY-MM-DD HH:mm:SS.S"

    global df

    # Extract the origin from the time_format string
    # "days since 1985-01-01 00:00:00 UTC" -> 1985-01-01
    origin_str = time_format.split("since ")[1]
    origin_str = origin_str.split(" ")[0]

    #origin_str = re.search('since (.*) ', time_format).group(1)

    # Convert the "TIME" column to datetime objects
    df['DATE'] = pd.to_datetime(df['NUM_TIME'], unit='D', origin=origin_str)

    df["YEAR"] = df["DATE"].dt.year
    df["MONTH"] = df["DATE"].dt.month
    df["DAY"] = df["DATE"].dt.day
    df["HOUR"] = df["DATE"].dt.hour

    df.to_csv("time_fixed_data.csv", index=False)

    print(f"Numerical times converted to dates and saved to time_fixed_data.csv")

folder_path = "/content/drive/MyDrive/Colab Notebooks/Colab Files/Wave_Wind_(42,-11)_(57,0)"
nc_file_one = os.listdir(folder_path)[0]
#time_format = nc.Dataset(nc_file_one, "r").variables["TIME"].units
time_format = "days since 1985-01-01 00:00:00 UTC"
num_to_date(time_format)
df.head()

"""* Reformat Num_Time column and save as new columns:

    Originally in "decimal days since 1985-01-01 00:00:00 UTC",

    Now available as decimal days, but also human-readable "YYYY-MM-DD HH:mm:SS.S" format.
"""

def fix_longitudes():

  global df

  df["LONGITUDE"] = df["LONGITUDE"] - 360

  df.to_csv("longitudes_fixed_data.csv", index=False)

  print("Longitudes fixed and saved to longitudes_fixed_data.csv")

fix_longitudes()
df.head()

"""* Convert Longitude from (0, 360) range to (-180, 180) range."""

def sort_by_time():
  global df
  df = df.sort_values(by=["NUM_TIME"])

  df.to_csv("sorted_data.csv", index=False)

  print("Data sorted by time and saved to sorted_data.csv")

sort_by_time()
df.head()

"""* Sort all entries in chronological order based off the Num_Time column.

# Data Sanitation
"""

df = df.dropna()
df.head()

"""* First, all NaN values were dropped."""

df_trimmed = df.copy()

#CHART ID 1

timeSeries_df = pd.DataFrame(columns=["NUM_TIME", "WAVE_HEIGHT", "DATE"])
timeSeries_df["NUM_TIME"] = round(df["NUM_TIME"], 0)
timeSeries_df["WAVE_HEIGHT"] = df["WAVE_HEIGHT"]
timeSeries_df["DATE"] = df["DATE"]
timeSeries_df = timeSeries_df.groupby(["NUM_TIME"]).mean()
timeSeries_df = timeSeries_df.reset_index()

timeSeries_df.head()

"""* A daily value for wave height was taken and stored to "timeSeries_df"
"""

#Chart ID 2

df_year_height = df_trimmed.groupby(["YEAR"]).mean()
df_year_height = df_year_height.reset_index()
df_year_height = df_year_height.drop(["NUM_TIME", "LATITUDE", "LONGITUDE", "BOT_DEPTH", "DATE", "MONTH", "DAY", "HOUR"], axis=1)
df_year_height.head()

"""* The mean wave height per year was calculated and stored to "df_year_height"
"""

#Chart ID 3

df_bymonth = df.copy()
df_bymonth = df_bymonth.groupby("MONTH").mean()
df_bymonth = df_bymonth.reset_index()

heights = df_bymonth["WAVE_HEIGHT"].tolist()

# fit amplitude, frequency and phase
amplitude, frequency, phase = sin_param_estimate(heights)
y_offset = np.mean(heights)

fitCoefficients = [y_offset, amplitude, frequency, phase]
print(fitCoefficients)
df_bymonth.head()

"""* The mean wave height per month was calculated and stored to "df_bymonth".

* A cosine wave was calculated and fit to the monthly mean wave height data, and the coefficients were stored to "fitCoefficients".
"""

#Chart ID 4

df_means = df_trimmed.copy()

df_means["NUM_TIME"] = round(df_means["NUM_TIME"], -2)

df_means["LATITUDE"] = round(df["LATITUDE"], 1)
df_means["LATITUDE"]

df_means["LONGITUDE"] = round(df["LONGITUDE"], 1)
df_means["LONGITUDE"]

df_loc_height = df_means.groupby(["LATITUDE", "LONGITUDE"]).mean()
df_loc_height = df_loc_height.reset_index()

df_loc_height = df_loc_height.drop(["NUM_TIME", "BOT_DEPTH", "DATE", "MONTH", "DAY", "HOUR", "YEAR"], axis=1)
df_loc_height.head()

"""* The mean wave height over location, to the nearest 0.1° Latitude and 0.1° Longitude was calculated and stored to "df_loc_height"

# Export
"""

# Create a new DataFrame to be exported
export_df = pd.DataFrame(columns=['Time', 'Height0', 'Year', 'MHeight1', 'MHeight2', 'FitCoefficients', 'lati', 'longi', 'MHeight3'])

# Populate the DataFrame with data from existing DataFrames
export_df['Time'] = timeSeries_df['DATE']
export_df['Height0'] = round(timeSeries_df['WAVE_HEIGHT'], 2)
export_df['Year'] = round(df_year_height["YEAR"], 0)
export_df['MHeight1'] = round(df_year_height['WAVE_HEIGHT'], 2)
export_df['MHeight2'] = round(df_bymonth['WAVE_HEIGHT'], 2)

for index in range(len(fitCoefficients)):
  export_df.loc[index, 'FitCoefficients'] = fitCoefficients[index]

export_df['lati'] = round(df_loc_height['LATITUDE'], 1)
export_df['longi'] = round(df_loc_height['LONGITUDE'], 1)
export_df['MHeight3'] = round(df_loc_height['WAVE_HEIGHT'], 2)

export_df.head()

"""* The columns from "timeSeries_df", "df_year_height", "df_bymonth", and "df_loc_height" were copied over to a new dataframe to be exported.

* The list, "fitCoefficients" was inserted into "df_loc_height" as it could not be copied directly without introducing many NaN entries to the data.

* Values could be rounded to a suitable number of decimal places to reduce the size of the resulting csv.
"""

export_df.to_csv("export.csv", index=False)
print("export_df saved to csv as \"export.csv\"")

"""# Display"""

plt.scatter(timeSeries_df['DATE'], timeSeries_df['WAVE_HEIGHT'], s=0.5)
plt.xlabel('Time (Years)')
plt.ylabel('Wave Height (m)')
plt.title('Daily Wave Heights since 1985')
plt.show()

"""* A Scatter Plot showing daily wave heights over the entire 34 year span."""

n = np.arange(0, df_bymonth['WAVE_HEIGHT'].count(), 1)
x = np.arange(0, df_bymonth['WAVE_HEIGHT'].count(), 1)

# plot result
plt.plot(x, heights, ".", label='input data')
plt.plot(y_offset + amplitude *np.cos(2 * np.pi * frequency * n + phase), 'red', label='fitted cosine')
plt.xlabel('Month')
plt.xticks(x, ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])
plt.ylabel('Mean Wave Height (m)')
plt.legend()
plt.title('Mean Wave Height per Month')
print(heights)

"""* A Scatter Plot showing the relationship between Month and mean Wave Height.
* A clear, sinusoidal relationship can be seen. This is drawn with a fitted cosine calculated with PyEstimate's "sin_param_estimate()" function.
"""

plt.bar(df_year_height["YEAR"], df_year_height["WAVE_HEIGHT"])
plt.xlabel("Time (Years)")
plt.ylabel("Mean Wave Height (m)")
plt.title("Mean Wave Height per Year")

"""* A Bar Chart illustrating mean Wave Height per Year
* No obvious patterns or trends to be seen.
* Gap in data from 1990 -Matches information about IMOS dataset.
"""

cmap = plt.get_cmap("viridis")
norm = colors.Normalize(vmin=min(df_loc_height["WAVE_HEIGHT"]), vmax=max(df_loc_height["WAVE_HEIGHT"]))  # Normalize y values

plt.scatter(df_loc_height["LONGITUDE"], df_loc_height["LATITUDE"], c=df_loc_height["WAVE_HEIGHT"]*5, cmap=cmap, norm=norm, s=3, marker="s")

plt.ylabel("Latitude")
plt.xlabel("Longitude")
plt.colorbar(label="Mean Wave Height (m)") # Add a colorbar to show the mapping

plt.title("Height Map of mean Wave Heights in the NE Atlantic")
plt.show()

"""* Height Map of mean wave heights of the area surrounding Ireland, Great Britain, and the Bay of Biscay.
* Heights are communicated using a colour scale, explained using a colour bar legend.
"""